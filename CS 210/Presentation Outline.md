Hi everyone. Today I am going to argue that the government use of **AI powered facial recognition** for public surveillance is **unethical**. 

Nowadays, we get more and more surveillance camera setup in the city, where the camera could take image of people on the street, and send them to a database, where AI could then detect the people using face recognition, and then the government could anyone appear at a certain location at certain time. This is an **emerging technology** as more surveillance camera are being set up and the facial recognition technology become mature.

So let’s now apply **Tavani’s method**. First, this technology is certainly **morally opaque**, on one side it **enhance public safety** if government could use it to trace down criminals, but on the other side it could also be **misused by government** to trace down the dissidents. For existing laws and ethical codes, there are **4th amendment** that largely emphasizes the **accessibility privacy and decisional privacy**, but not the informational privacy, in which case the camera certain tracks down **PII** (personal identifiable information here), and we see a policy vacuum here. The existing **ACM code** says that computing professional need to “respect privacy”. There is also an **conceptual muddle**, see that technology  used here, really blurred the line between “security surveillance” and “mass tracking” here. The existence of policy vacuum and conceptual muddles here really poses this as an ethical question.

Now, I am going to use **act utilitarian ethic** to argue that this facial recognition is unethical. Yes, this system could potentially help law enforcement to trace down criminals, enhancing everyone’s security, but it is at cost of everyone’s privacy. First, since all the personal identifiable data is highly sensitive, considering all the location data of individuals, i**f there is ever a leak of information**, the consequence is devastating. Considering the probability that such a system is hacked by criminals, the **security risk** imposes on everyone easily outweigh the benefits. Second, it is also extremely prone to misuse. Since these data are highly sensitive, its use are internal for government, and it is likely it could be targeted at individuals. Mass surveillance already happened in Iran to **enforce dress code**, and happened in China to **systematically track down political dissidents**. Third, the journal *Nature* reveals that minority groups suffer significant biases from these AI models. The models are going to make more error for people of color, and could potentially recognize them as someone else, maybe a criminal.

Therefore, it’s unethical for the government to use of **AI powered facial recognition** for public surveillance. 





